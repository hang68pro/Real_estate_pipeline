# Real_estate_pipeline
Real Estate Data Pipeline: End-to-end ETL pipeline extracting, transforming, and loading housing market data from Redfin into SQLite and AWS S3 using Python and pandas.
# ğŸ¡ Real Estate Data Pipeline

This project builds a complete data pipeline that extracts housing market data from Redfin, cleans and transforms the dataset, stores it in SQLite, and optionally uploads a versioned Parquet file to AWS S3. The pipeline is modular, using Python scripts organized by ETL phase.

## ğŸ”§ Tech Stack
- Python 3.10
- Pandas
- SQLAlchemy (SQLite)
- Parquet (via `pandas`)
- AWS S3 (via Boto3)
- Docker (optional)
- Redfin Housing Market CSVs

## ğŸ“ Pipeline Structure
```bash
real_estate_pipeline/
â”œâ”€â”€ data/                  # Raw CSVs from Redfin
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py         # Reads CSV
â”‚   â”œâ”€â”€ transform.py       # Cleans & reshapes data
â”‚   â””â”€â”€ load.py            # Saves to SQLite & Parquet
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py        # AWS / DB paths
â”œâ”€â”€ output/                # Versioned Parquet outputs
â”œâ”€â”€ pipeline.py            # Runs full pipeline
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                   # AWS credentials (excluded from Git)
â””â”€â”€ README.md

ğŸ“¦ Example Output
output/2025-08/redfin_data.parquet

real_estate.db with a redfin_data table

ğŸš€ Future Add-ons
Dockerized container for deployment

Airflow DAG for automation

Visualizations of market trends
